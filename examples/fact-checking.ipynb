{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "572fb209",
   "metadata": {},
   "source": [
    "# Fact Checking\n",
    "A simple example on how to use the vector database for a fact-checking system with Wikidata statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e537c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Fact-Checker/1.0 (embeddings@wikimedia.de)'\n",
    "}\n",
    "LANG = 'en'\n",
    "INCLUDE_EXTERNAL_IDS = False\n",
    "\n",
    "# Define the claim to be checked\n",
    "claim = 'Albert Einstein was a theoretical physicist who developed the theory of relativity.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4f435b",
   "metadata": {},
   "source": [
    "### Get from the vector database the Wikidata items and properties that are relevant to the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabfcfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get relevant Wikidata items\n",
    "items = requests.get(\n",
    "    'https://wd-vectordb.wmcloud.org/item/query',\n",
    "    params={'query': claim, 'lang': LANG},\n",
    "    headers=HEADERS,\n",
    ")\n",
    "items = items.json()\n",
    "\n",
    "# Get relevant Wikidata properties\n",
    "properties = requests.get(\n",
    "    'https://wd-vectordb.wmcloud.org/property/query',\n",
    "    params={'query': claim, 'lang': LANG},\n",
    "    headers=HEADERS,\n",
    ")\n",
    "properties = properties.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d48551",
   "metadata": {},
   "source": [
    "### Get all statements of each item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b14d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statements(qid):\n",
    "    params = {\n",
    "        'id': qid,\n",
    "        'external_ids': INCLUDE_EXTERNAL_IDS,\n",
    "        'format': 'json'\n",
    "    }\n",
    "\n",
    "    url = \"https://wd-textify.toolforge.org\"\n",
    "    results = requests.get(url, params=params, headers=HEADERS)\n",
    "    results.raise_for_status()\n",
    "\n",
    "    text = results.json()\n",
    "    return text\n",
    "\n",
    "for i in range(len(items)):\n",
    "    item_info = get_statements(items[i]['QID'])\n",
    "    items[i]['label'] = item_info['label']\n",
    "    items[i]['claims'] = item_info['claims']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ab4cdd",
   "metadata": {},
   "source": [
    "### Sort statements by vector similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7e34a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_statements = []\n",
    "for item in items:\n",
    "    for property in properties:\n",
    "        for statement in item['claims']:\n",
    "            if property['PID'] == claim['PID']:\n",
    "                result_statements.append({\n",
    "                    'statement': {\n",
    "                        **statement,\n",
    "                        'QID': item['QID'],\n",
    "                        'item_label': item['label'],\n",
    "                    },\n",
    "                    'similarity_score': item['similarity_score'] * property['similarity_score']\n",
    "                })\n",
    "\n",
    "# Sort by similarity score\n",
    "result_statements = sorted(result_statements, key=lambda x: x['similarity_score'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77ff4a3",
   "metadata": {},
   "source": [
    "### Prepare NLI model for textual entailment detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58f60d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "model_name = \"MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "def predict_entailment(premise, hypothesis):\n",
    "    input = tokenizer(premise, hypothesis, truncation=True, return_tensors=\"pt\")\n",
    "    output = model(input[\"input_ids\"].to(device))\n",
    "    prediction = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
    "    label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "    prediction = {name: round(float(pred) * 100, 1) for pred, name in zip(prediction, label_names)}\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e325418a",
   "metadata": {},
   "source": [
    "### Prepare hypothesis from Wikidata statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c3f367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_to_string(value):\n",
    "    if isinstance(value, str):\n",
    "        return value\n",
    "    if 'string' in value:\n",
    "        return value['string']\n",
    "    elif 'label' in value:\n",
    "        return value['label']\n",
    "    elif 'time' in value:\n",
    "        return value['time']\n",
    "    return str(value)\n",
    "\n",
    "def prepare_hypothesis(result):\n",
    "    hypothesis = \"\"\n",
    "    for statement in result['values']:\n",
    "        hypothesis += f\"{result['item_label']}: {result['property_label']}: {value_to_string(statement['value'])}\"\n",
    "        if 'qualifiers' in statement:\n",
    "            for qualifier in statement['qualifiers']:\n",
    "                values = ', '.join([\n",
    "                    value_to_string(v['value']) for v in qualifier['values']\n",
    "                ])\n",
    "                hypothesis += f\" | {qualifier['property_label']}: {values}\"\n",
    "        hypothesis += \"\\n\"\n",
    "    return hypothesis.strip()\n",
    "\n",
    "for i in range(len(result_statements)):\n",
    "    result_statements[i]['hypothesis'] = prepare_hypothesis(result_statements[i]['statement'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701381af",
   "metadata": {},
   "source": [
    "### Predict Entailment per Wikidata statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2719276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(result_statements)):\n",
    "    result_statements[i]['entailment'] = predict_entailment(claim, result_statements[i]['hypothesis'])\n",
    "\n",
    "# Sort by similarity score\n",
    "result_statements = sorted(result_statements, key=lambda x: x['entailment']['neutral'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d2587e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theory of relativity: discoverer or inventor: Albert Einstein\n",
      "{'entailment': 98.1, 'neutral': 1.8, 'contradiction': 0.2}\n"
     ]
    }
   ],
   "source": [
    "print(result_statements[0]['hypothesis'])\n",
    "print(result_statements[0]['entailment'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
