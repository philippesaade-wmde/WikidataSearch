{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "572fb209",
   "metadata": {},
   "source": [
    "# Fact Checking\n",
    "A simple example on how to use the vector database for a fact-checking system with Wikidata statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e537c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Fact-Checker/1.0 (embeddings@wikimedia.de)'\n",
    "}\n",
    "LANG = 'en'\n",
    "INCLUDE_EXTERNAL_IDS = False\n",
    "\n",
    "# Define the claim to be checked\n",
    "claim = 'Albert Einstein was a theoretical physicist who developed the theory of relativity.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4f435b",
   "metadata": {},
   "source": [
    "### Get from the vector database the Wikidata items and properties that are relevant to the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eabfcfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get relevant Wikidata items\n",
    "items = requests.get(\n",
    "    'https://wd-vectordb.wmcloud.org/item/query',\n",
    "    params={'query': claim, 'lang': LANG},\n",
    "    headers=HEADERS,\n",
    ")\n",
    "items = items.json()\n",
    "\n",
    "# Get relevant Wikidata properties\n",
    "properties = requests.get(\n",
    "    'https://wd-vectordb.wmcloud.org/property/query',\n",
    "    params={'query': claim, 'lang': LANG, 'exclude_external_ids': True},\n",
    "    headers=HEADERS,\n",
    ")\n",
    "properties = properties.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d48551",
   "metadata": {},
   "source": [
    "### Get all statements of each item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b14d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statements(qid, pids):\n",
    "    params = {\n",
    "        'id': qid,\n",
    "        'pids': pids,\n",
    "        'external_ids': INCLUDE_EXTERNAL_IDS,\n",
    "        'format': 'json'\n",
    "    }\n",
    "\n",
    "    url = \"https://wd-textify.toolforge.org\"\n",
    "    results = requests.get(url, params=params, headers=HEADERS)\n",
    "    results.raise_for_status()\n",
    "\n",
    "    text = results.json()\n",
    "    return text\n",
    "\n",
    "qids = [q['QID'] for q in items]\n",
    "pids = [p['PID'] for p in properties]\n",
    "items_info = get_statements(','.join(qids), ','.join(pids))\n",
    "\n",
    "for i in range(len(items)):\n",
    "    items[i]['label'] = items_info[items[i]['QID']]['label']\n",
    "    items[i]['claims'] = items_info[items[i]['QID']]['claims']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ab4cdd",
   "metadata": {},
   "source": [
    "### Sort statements by vector similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7e34a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_statements = []\n",
    "for item in items:\n",
    "    for property in properties:\n",
    "        for statement in item['claims']:\n",
    "            if property['PID'] == statement['PID']:\n",
    "                result_statements.append({\n",
    "                    'statement': {\n",
    "                        **statement,\n",
    "                        'QID': item['QID'],\n",
    "                        'item_label': item['label'],\n",
    "                    },\n",
    "                    'similarity_score': item['similarity_score'] * property['similarity_score']\n",
    "                })\n",
    "\n",
    "# Sort by similarity score\n",
    "result_statements = sorted(result_statements, key=lambda x: x['similarity_score'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77ff4a3",
   "metadata": {},
   "source": [
    "### Prepare NLI model for textual entailment detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58f60d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model_name = \"MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "\n",
    "def predict_entailment(claim, wd_fact):\n",
    "    label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "    input = tokenizer(wd_fact, claim, truncation=True, return_tensors=\"pt\")\n",
    "    output = model(input[\"input_ids\"].to(device))\n",
    "    prediction = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
    "    prediction = {name: round(float(pred) * 100, 1) for pred, name in zip(prediction, label_names)}\n",
    "    return prediction\n",
    "\n",
    "def predict_entailment_bulk(claim, wd_facts, batch_size=8):\n",
    "    label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(wd_facts), batch_size):\n",
    "            batch_premises = wd_facts[i:i + batch_size]\n",
    "\n",
    "            # Premise varies, hypothesis (claim) is the same\n",
    "            enc = tokenizer(\n",
    "                batch_premises,\n",
    "                [claim] * len(batch_premises),\n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "            enc = {k: v.to(device) for k, v in enc.items()}\n",
    "\n",
    "            out = model(**enc)\n",
    "            probs = torch.softmax(out.logits, dim=-1).cpu()\n",
    "\n",
    "            for row in probs:\n",
    "                row_dict = {\n",
    "                    name: round(float(p) * 100, 1)\n",
    "                    for name, p in zip(label_names, row)\n",
    "                }\n",
    "                results.append(row_dict)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e325418a",
   "metadata": {},
   "source": [
    "### Prepare hypothesis from Wikidata statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c3f367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_to_string(value):\n",
    "    if isinstance(value, str):\n",
    "        return value\n",
    "    if 'string' in value:\n",
    "        return value['string']\n",
    "    elif 'label' in value:\n",
    "        return value['label']\n",
    "    elif 'time' in value:\n",
    "        return value['time']\n",
    "    return str(value)\n",
    "\n",
    "def prepare_hypothesis(result):\n",
    "    hypothesis = \"\"\n",
    "    for statement in result['values']:\n",
    "        hypothesis += f\"{result['item_label']}: {result['property_label']}: {value_to_string(statement['value'])}\"\n",
    "        if 'qualifiers' in statement:\n",
    "            for qualifier in statement['qualifiers']:\n",
    "                values = ', '.join([\n",
    "                    value_to_string(v['value']) for v in qualifier['values']\n",
    "                ])\n",
    "                hypothesis += f\" | {qualifier['property_label']}: {values}\"\n",
    "        hypothesis += \"\\n\"\n",
    "    return hypothesis.strip()\n",
    "\n",
    "for i in range(len(result_statements)):\n",
    "    result_statements[i]['hypothesis'] = prepare_hypothesis(result_statements[i]['statement'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701381af",
   "metadata": {},
   "source": [
    "### Predict Entailment per Wikidata statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c852735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_entailment_bulk(\n",
    "    claim,\n",
    "    [result_statements[i]['hypothesis'] for i in range(len(result_statements))],\n",
    "    batch_size=8\n",
    ")\n",
    "for i in range(len(result_statements)):\n",
    "    result_statements[i]['entailment'] = predictions[i]\n",
    "\n",
    "# Sort by similarity score\n",
    "result_statements = sorted(result_statements, key=lambda x: x['entailment']['neutral'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d2587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_statements[0]['hypothesis'])\n",
    "print(result_statements[0]['entailment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ef1e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import requests\n",
    "\n",
    "class FactChecker:\n",
    "    def __init__(self, include_external_ids=False, lang='en', device='cpu'):\n",
    "        self.include_external_ids = include_external_ids\n",
    "        self.lang = lang\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Fact-Checker/1.0 (embeddings@wikimedia.de)'\n",
    "        }\n",
    "\n",
    "        model_name = \"MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli\"\n",
    "\n",
    "        self.device = torch.device(device)\n",
    "        self.nli_labels = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "        self.nli_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.nli_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    def check_claim(self, claim, verbose=False):\n",
    "        if verbose:\n",
    "            print(f\"Vector Search...\")\n",
    "        items, properties = self.vector_search(claim)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Getting Statements Text...\")\n",
    "        statements = self.prepare_statements(items, properties)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Found {len(statements)} statements\")\n",
    "\n",
    "        for i in range(len(statements)):\n",
    "            statements[i]['hypothesis'] = self.statement_to_string(\n",
    "                statements[i]['statement']\n",
    "            )\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Predicting Entailment...\")\n",
    "        predictions = self.predict_entailment(\n",
    "            claim,\n",
    "            [statements[i]['hypothesis'] for i in range(len(statements))],\n",
    "            batch_size=8\n",
    "        )\n",
    "        for i in range(len(statements)):\n",
    "            statements[i]['entailment'] = predictions[i]\n",
    "\n",
    "        # Sort by neutrality\n",
    "        statements = sorted(statements, key=lambda x: x['entailment']['neutral'])\n",
    "\n",
    "        return statements\n",
    "\n",
    "    def vector_search(self, claim):\n",
    "        # Get relevant Wikidata items\n",
    "        items = requests.get(\n",
    "            'https://wd-vectordb.wmcloud.org/item/query',\n",
    "            params={'query': claim, 'lang': self.lang},\n",
    "            headers=self.headers,\n",
    "        )\n",
    "        items = items.json()\n",
    "\n",
    "        # Get relevant Wikidata properties\n",
    "        properties = requests.get(\n",
    "            'https://wd-vectordb.wmcloud.org/property/query',\n",
    "            params={'query': claim, 'lang': self.lang, 'exclude_external_ids': True},\n",
    "            headers=self.headers,\n",
    "        )\n",
    "        properties = properties.json()\n",
    "\n",
    "        return items, properties\n",
    "\n",
    "    def get_item_statements(self, qids, pids):\n",
    "        params = {\n",
    "            'id': qids,\n",
    "            'pids': pids,\n",
    "            'external_ids': self.include_external_ids,\n",
    "            'format': 'json'\n",
    "        }\n",
    "\n",
    "        url = \"https://wd-textify.toolforge.org\"\n",
    "        results = requests.get(url, params=params, headers=self.headers)\n",
    "        results.raise_for_status()\n",
    "\n",
    "        text = results.json()\n",
    "        return text\n",
    "\n",
    "    def statement_to_string(self, statement):\n",
    "        hypothesis = f\"{statement['item_label']}: {statement['property_label']}: \"\n",
    "        for svalue in statement['values']:\n",
    "            hypothesis += f\"{self.statement_value_to_string(svalue['value'])}\"\n",
    "\n",
    "            if 'qualifiers' in svalue:\n",
    "                for qualifier in svalue['qualifiers']:\n",
    "                    values = ', '.join([\n",
    "                        self.statement_value_to_string(v['value']) for v in qualifier['values']\n",
    "                    ])\n",
    "                    hypothesis += f\" ({qualifier['property_label']}: {values})\"\n",
    "\n",
    "            hypothesis += \", \"\n",
    "        return hypothesis.strip().rstrip(',')\n",
    "\n",
    "    def statement_value_to_string(self, value):\n",
    "        if isinstance(value, str):\n",
    "            return value\n",
    "        if 'string' in value:\n",
    "            return value['string']\n",
    "        elif 'label' in value:\n",
    "            return value['label']\n",
    "        elif 'time' in value:\n",
    "            return value['time']\n",
    "        return str(value)\n",
    "\n",
    "    def prepare_statements(self, items, properties):\n",
    "        qids = [q['QID'] for q in items]\n",
    "        pids = [p['PID'] for p in properties]\n",
    "        items_info = self.get_item_statements(','.join(qids), ','.join(pids))\n",
    "\n",
    "        for i in range(len(items)):\n",
    "            items[i]['label'] = items_info[items[i]['QID']]['label']\n",
    "            items[i]['claims'] = items_info[items[i]['QID']]['claims']\n",
    "\n",
    "        result_statements = []\n",
    "        for item in items:\n",
    "            for property in properties:\n",
    "                for statement in item['claims']:\n",
    "                    if property['PID'] == statement['PID']:\n",
    "                        result_statements.append({\n",
    "                            'statement': {\n",
    "                                **statement,\n",
    "                                'QID': item['QID'],\n",
    "                                'item_label': item['label'],\n",
    "                            },\n",
    "                            'similarity_score': item['similarity_score'] * property['similarity_score']\n",
    "                        })\n",
    "\n",
    "        # Sort by similarity score\n",
    "        result_statements = sorted(result_statements, key=lambda x: x['similarity_score'], reverse=True)\n",
    "        return result_statements\n",
    "\n",
    "    def predict_entailment(self, claim, premises, batch_size = 8):\n",
    "        results = []\n",
    "\n",
    "        self.nli_model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(premises), batch_size):\n",
    "                batch_premises = premises[i:i + batch_size]\n",
    "\n",
    "                enc = self.nli_tokenizer(\n",
    "                    batch_premises,\n",
    "                    [claim] * len(batch_premises),\n",
    "                    truncation=True,\n",
    "                    padding=True,\n",
    "                    return_tensors=\"pt\",\n",
    "                )\n",
    "\n",
    "                enc = {k: v.to(self.device) for k, v in enc.items()}\n",
    "\n",
    "                out = self.nli_model(**enc)\n",
    "                probs = torch.softmax(out.logits, dim=-1).cpu()\n",
    "\n",
    "                for row in probs:\n",
    "                    row_dict = {\n",
    "                        name: round(float(p) * 100, 1)\n",
    "                        for name, p in zip(self.nli_labels, row)\n",
    "                    }\n",
    "                    results.append(row_dict)\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a582e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philippe.saade/anaconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q478214', 'Q317521', 'Q4920135', 'Q20718232', 'Q46845259', 'Q86349924', 'Q107749604', 'Q17085152', 'Q40008974', 'Q16900721', 'Q78163092', 'Q28221306', 'Q109334610', 'Q115619373', 'Q75327597', 'Q54959143', 'Q55642234', 'Q156238', 'Q58811108', 'Q4645801', 'Q5367351', 'Q80088527', 'Q59773555', 'Q30873', 'Q111043538', 'Q107394758', 'Q20687182', 'Q5357530', 'Q105966435', 'Q98356352', 'Q54173', 'Q20529164', 'Q123565578', 'Q57060073', 'Q42417740', 'Q7875985', 'Q39328518', 'Q1960330', 'Q17068357', 'Q97286528', 'Q16993862', 'Q753571', 'Q1326458', 'Q18891264', 'Q4645564', 'Q5374879', 'Q12482376', 'Q5357420', 'Q1326392', 'Q6883039']\n",
      "['P618', 'P112', 'P169', 'P8324', 'P12642', 'P1079', 'P127', 'P4140', 'P8340', 'P7936', 'P2010', 'P2137', 'P1951', 'P3320', 'P2200', 'P622', 'P2009', 'P3362', 'P375', 'P2226', 'P12621', 'P516', 'P2228', 'P61', 'P1789', 'P1056', 'P2403', 'P1071', 'P450', 'P930', 'P2295', 'P2160', 'P2201', 'P2436', 'P2791', 'P2139', 'P1830', 'P859', 'P6589', 'P619', 'P12221', 'P4519', 'P488']\n",
      "Tesla, Inc.: founded by: Martin Eberhard, Marc Tarpenning\n",
      "{'entailment': 0.1, 'neutral': 0.2, 'contradiction': 99.7}\n",
      "\n",
      "Tesla Electric Light & Manufacturing: founded by: Nikola Tesla\n",
      "{'entailment': 0.0, 'neutral': 0.3, 'contradiction': 99.7}\n",
      "\n",
      "Elon Musk: owner of: Tesla, Inc., X.com, Elon Musk's Tesla Roadster, SpaceX, The Boring Company, X (start time: April 2022), X Holdings I, Inc., X Holdings II, Inc., X Holdings III, LLC\n",
      "{'entailment': 96.9, 'neutral': 3.1, 'contradiction': 0.1}\n",
      "\n",
      "Dell: chief executive officer: Michael Dell\n",
      "{'entailment': 1.5, 'neutral': 22.9, 'contradiction': 75.6}\n",
      "\n",
      "Mapbox: chief executive officer: Peter Sirota (start time: March 1, 2021) (reason for preferred rank: most recent value)\n",
      "{'entailment': 0.8, 'neutral': 29.6, 'contradiction': 69.5}\n",
      "\n",
      "Woz U: owned by: Steve Wozniak\n",
      "{'entailment': 0.7, 'neutral': 48.5, 'contradiction': 50.7}\n",
      "\n",
      "Dell: owner of: Alienware, Dell Wyse, Perot Systems, Dell AppAssure, Ocarina Networks, Dell\n",
      "{'entailment': 5.1, 'neutral': 53.0, 'contradiction': 41.9}\n",
      "\n",
      "ExxonMobil: owner of: Imperial Oil, Esso, ExxonMobil Australia, Exxon Neftegas, Aera Energy (proportion: {'amount': '+48.2', 'unit': 'percent', 'unit_QID': 'Q11229'}), Forbes Travel Guide\n",
      "{'entailment': 10.3, 'neutral': 71.5, 'contradiction': 18.2}\n",
      "\n",
      "General Electric: owner of: Allendale Square, America's Talking, Dowty Rotol, GE Oil and Gas, National Broadcasting Company, GE Transportation, GE Wind Energy, Baker Hughes, GE Capital, GE HealthCare, GE Capital Aviation Services, GE Aerospace, GE Water, TMBThanachart Bank PCL., British Broadcasting Company Limited, Trump International Hotel and Tower, Wabtec, Tungsram (start time: 1989) (end time: 2018)\n",
      "{'entailment': 3.6, 'neutral': 71.6, 'contradiction': 24.8}\n",
      "\n",
      "Mapbox: owner of: Mapbox San Francisco, Mapbox D.C., MeatText (start time: January 16, 2013), Human (start time: August 17, 2016), Mapbox Japan\n",
      "{'entailment': 1.1, 'neutral': 76.1, 'contradiction': 22.8}\n",
      "\n",
      "Tesla, Inc.: owned by: Elon Musk (proportion: +0.208) (point in time: December 31, 2019), Baillie Gifford (proportion: +0.076) (point in time: December 31, 2019), Capital Ventures International (proportion: +0.067) (point in time: December 31, 2019), Capital Group Companies (proportion: +0.059) (point in time: December 31, 2019), Larry Ellison (proportion: +0.017) (point in time: December 31, 2019)\n",
      "{'entailment': 20.2, 'neutral': 79.7, 'contradiction': 0.1}\n",
      "\n",
      "Dell: founded by: Michael Dell\n",
      "{'entailment': 2.8, 'neutral': 84.2, 'contradiction': 13.0}\n",
      "\n",
      "General Electric: chief executive officer: H. Lawrence Culp Jr. (start time: October 1, 2018)\n",
      "{'entailment': 1.2, 'neutral': 84.4, 'contradiction': 14.4}\n",
      "\n",
      "Dell: product or material produced: desktop computer, laptop, server computer, peripheral, smartphone, networking hardware, software, computer mouse, computer keyboard, motherboard, sound card, computer monitor, data storage medium, printer, computer, computer system\n",
      "{'entailment': 6.4, 'neutral': 87.0, 'contradiction': 6.6}\n",
      "\n",
      "Elektra: product or material produced: espresso machine\n",
      "{'entailment': 1.8, 'neutral': 87.4, 'contradiction': 10.8}\n",
      "\n",
      "Bolt: board member: Markus Villig\n",
      "{'entailment': 0.9, 'neutral': 88.6, 'contradiction': 10.6}\n",
      "\n",
      "Elron: product or material produced: rail transport\n",
      "{'entailment': 2.2, 'neutral': 89.4, 'contradiction': 8.4}\n",
      "\n",
      "Mapbox: chairperson: Eric Gundersen (start time: 2010)\n",
      "{'entailment': 1.6, 'neutral': 89.7, 'contradiction': 8.7}\n",
      "\n",
      "General Electric: product or material produced: aircraft engine\n",
      "{'entailment': 8.2, 'neutral': 89.8, 'contradiction': 2.0}\n",
      "\n",
      "Mapbox: product or material produced: software\n",
      "{'entailment': 5.9, 'neutral': 92.3, 'contradiction': 1.8}\n",
      "\n",
      "Tesla, Inc.: board member: Elon Musk (start time: 2004), Robyn Denholm (start time: 2014), Larry Ellison (start time: 2018) (end time: August 4, 2022), Ira Ehrenpreis (start time: 2007), Hiromichi Mizuno (start time: April 2020) (end time: May 2023), James Murdoch (start time: July 13, 2017), Kimbal Musk (start time: 2004), Kathleen Wilson-Thompson (start time: December 27, 2018), Joe Gebbia (start time: September 25, 2022), J. B. Straubel (start time: May 16, 2023)\n",
      "{'entailment': 6.1, 'neutral': 93.7, 'contradiction': 0.1}\n",
      "\n",
      "Dell: owned by: Dell Technologies\n",
      "{'entailment': 2.9, 'neutral': 94.2, 'contradiction': 2.9}\n",
      "\n",
      "Mapbox: funder: John S. and James L. Knight Foundation (point in time: September 2013) (capital cost: {'amount': '+575000', 'unit': 'United States dollar', 'unit_QID': 'Q4917'}) (has goal: iD)\n",
      "{'entailment': 1.0, 'neutral': 95.2, 'contradiction': 3.7}\n",
      "\n",
      "Bolt: founded by: Markus Villig\n",
      "{'entailment': 0.3, 'neutral': 95.4, 'contradiction': 4.4}\n",
      "\n",
      "ExxonMobil: chief executive officer: Darren Woods (start time: 2017)\n",
      "{'entailment': 0.6, 'neutral': 95.5, 'contradiction': 3.9}\n",
      "\n",
      "Mapbox: founded by: Eric Gundersen, Bonnie Bogle\n",
      "{'entailment': 0.4, 'neutral': 95.6, 'contradiction': 4.0}\n",
      "\n",
      "General Electric: owned by: T. Rowe Price, The Vanguard Group, Capital Group Companies, Fidelity Investments, BlackRock, Northern Trust\n",
      "{'entailment': 2.5, 'neutral': 95.7, 'contradiction': 1.8}\n",
      "\n",
      "Energy Vault: founded by: Bill Gross\n",
      "{'entailment': 0.4, 'neutral': 96.9, 'contradiction': 2.8}\n",
      "\n",
      "ExxonMobil: founded by: John D. Rockefeller\n",
      "{'entailment': 0.7, 'neutral': 97.2, 'contradiction': 2.1}\n",
      "\n",
      "Dell: board member: Michael Dell, David Dorman (start time: September 2016), Egon Durban (start time: October 2013), David Grain (start time: September 2021), Bill Green (start time: September 2016), Ellen Kullman (start time: September 2016), Simon Patterson (start time: October 2013), Lynn Vojvodich (start time: April 2019)\n",
      "{'entailment': 1.0, 'neutral': 97.2, 'contradiction': 1.8}\n",
      "\n",
      "Mapbox: board member: Ira Ehrenpreis (start time: 2015), Eric Gundersen\n",
      "{'entailment': 0.6, 'neutral': 97.2, 'contradiction': 2.2}\n",
      "\n",
      "Tesla, Inc.: chairperson: Robyn Denholm (start time: November 2018) (object of statement has role: chairperson)\n",
      "{'entailment': 1.8, 'neutral': 97.5, 'contradiction': 0.7}\n",
      "\n",
      "Elang Mahkota Teknologi: founded by: Eddy Kusnadi Sariaatmadja\n",
      "{'entailment': 0.6, 'neutral': 97.7, 'contradiction': 1.8}\n",
      "\n",
      "Elon Musk's Tesla Roadster: owned by: Elon Musk\n",
      "{'entailment': 2.2, 'neutral': 97.8, 'contradiction': 0.0}\n",
      "\n",
      "General Electric: total revenue: {'amount': '+76555000000', 'unit': 'United States dollar', 'unit_QID': 'Q4917'} (point in time: 2022)\n",
      "{'entailment': 0.8, 'neutral': 97.9, 'contradiction': 1.3}\n",
      "\n",
      "Bolt: product or material produced: Bolt Food, Bolt\n",
      "{'entailment': 1.1, 'neutral': 98.0, 'contradiction': 0.9}\n",
      "\n",
      "General Electric: net profit: {'amount': '+225000000', 'unit': 'United States dollar', 'unit_QID': 'Q4917'} (point in time: 2022)\n",
      "{'entailment': 0.6, 'neutral': 98.1, 'contradiction': 1.3}\n",
      "\n",
      "General Electric: board member: H. Lawrence Culp Jr. (start time: 2018), Sébastien Bazin (start time: 2016), Ash Carter (start time: 2020), Francisco D'Souza (start time: 2013), Ed Garden (start time: 2017), Thomas Horton (start time: 2018), Risa Lavizzo-Mourey (start time: 2017), Catherine Lesjak (start time: 2019), Paula Rosput Reynolds (start time: 2018), Leslie Seidman (start time: 2018), James Tisch (start time: 2010) (end time: March 8, 2022), Stephen Angel (start time: March 7, 2022), Bella Goren (start time: March 7, 2022), Tom Mihaljevic (start time: April 11, 2022)\n",
      "{'entailment': 0.6, 'neutral': 98.2, 'contradiction': 1.2}\n",
      "\n",
      "General Electric: total equity: {'amount': '+37073000000', 'unit': 'United States dollar', 'unit_QID': 'Q4917'} (point in time: December 31, 2020)\n",
      "{'entailment': 0.7, 'neutral': 98.3, 'contradiction': 1.1}\n",
      "\n",
      "Energy Vault: product or material produced: potential energy\n",
      "{'entailment': 0.9, 'neutral': 98.3, 'contradiction': 0.8}\n",
      "\n",
      "Elron Ventures Ltd: founded by: Uzia Galil\n",
      "{'entailment': 0.1, 'neutral': 98.4, 'contradiction': 1.5}\n",
      "\n",
      "Bolt: investor: Fidelity Investments, Sequoia Capital, International Finance Corporation, D1 Capital Partners, European Investment Bank, Mercedes-Benz Group, DiDi\n",
      "{'entailment': 0.3, 'neutral': 98.5, 'contradiction': 1.2}\n",
      "\n",
      "Elon Musk's Tesla Roadster: space launch vehicle: Falcon Heavy (serial number: 001)\n",
      "{'entailment': 1.4, 'neutral': 98.6, 'contradiction': 0.0}\n",
      "\n",
      "Dell: total revenue: {'amount': '+102301000000', 'unit': 'United States dollar', 'unit_QID': 'Q4917'} (point in time: 2022) (start time: January 29, 2022) (end time: February 3, 2023)\n",
      "{'entailment': 0.5, 'neutral': 98.6, 'contradiction': 0.8}\n",
      "\n",
      "Elon Musk's Tesla Roadster: UTC date of spacecraft launch: February 6, 2018 (refine date: 20:45)\n",
      "{'entailment': 1.3, 'neutral': 98.7, 'contradiction': 0.0}\n",
      "\n",
      "ExxonMobil: owned by: The Vanguard Group (proportion: +0.084) (point in time: December 31, 2019)\n",
      "{'entailment': 0.8, 'neutral': 98.7, 'contradiction': 0.6}\n",
      "\n",
      "General Electric: market capitalization: {'amount': '+114920000000', 'unit': 'United States dollar', 'unit_QID': 'Q4917'} (point in time: August 26, 2021)\n",
      "{'entailment': 0.6, 'neutral': 98.7, 'contradiction': 0.7}\n",
      "\n",
      "General Electric: total assets: {'amount': '+253452000000', 'unit': 'United States dollar', 'unit_QID': 'Q4917'} (point in time: December 31, 2020)\n",
      "{'entailment': 0.5, 'neutral': 98.7, 'contradiction': 0.8}\n",
      "\n",
      "Tesla, Inc.: chief executive officer: Elon Musk (start time: October 2008) (replaces: Ze'ev Drori)\n",
      "{'entailment': 0.3, 'neutral': 98.8, 'contradiction': 1.0}\n",
      "\n",
      "Elon Musk's Tesla Roadster: launch contractor: SpaceX\n",
      "{'entailment': 1.2, 'neutral': 98.8, 'contradiction': 0.0}\n",
      "\n",
      "Mapbox: business model: software as a service\n",
      "{'entailment': 0.9, 'neutral': 98.8, 'contradiction': 0.3}\n",
      "\n",
      "Dell: market capitalization: {'amount': '+57000000000', 'unit': 'United States dollar', 'unit_QID': 'Q4917'} (point in time: January 2021)\n",
      "{'entailment': 0.6, 'neutral': 98.8, 'contradiction': 0.6}\n",
      "\n",
      "Dell: net profit: {'amount': '+2442000000', 'unit': 'United States dollar', 'unit_QID': 'Q4917'} (point in time: 2022) (start time: January 29, 2022) (end time: February 3, 2023)\n",
      "{'entailment': 0.3, 'neutral': 98.9, 'contradiction': 0.7}\n",
      "\n",
      "ExxonMobil: board member: Darren Woods (start time: January 1, 2016), Michael J. Angelakis (start time: March 1, 2021), Susan Avery (start time: February 1, 2017), Angela Braly (start time: May 25, 2016), Ursula Burns (start time: November 27, 2012) (end time: May 31, 2023), Kenneth Frazier (start time: May 27, 2009) (end time: May 25, 2022), Gregory J. Goff (start time: May 26, 2021), Kaisa Hietala (start time: May 26, 2021), Jay Hooley (start time: January 1, 2020), Steven A. Kandarian (start time: February 1, 2018), Andy Karsner (start time: June 2, 2021), Jeffrey W. Ubben (start time: March 1, 2021), John Harris (start time: January 1, 2023), Larry Kellner (start time: January 1, 2023)\n",
      "{'entailment': 0.2, 'neutral': 99.0, 'contradiction': 0.7}\n",
      "\n",
      "General Electric: founded by: Thomas Edison, Elihu Thomson, Charles A. Coffin, Edwin J. Houston\n",
      "{'entailment': 0.3, 'neutral': 99.1, 'contradiction': 0.6}\n",
      "\n",
      "ExxonMobil: product or material produced: gasoline, lubricant\n",
      "{'entailment': 0.8, 'neutral': 99.1, 'contradiction': 0.1}\n",
      "\n",
      "Dell: operating income: {'amount': '+5771000000', 'unit': 'United States dollar', 'unit_QID': 'Q4917'} (point in time: 2022) (start time: January 29, 2022) (end time: February 3, 2023)\n",
      "{'entailment': 0.3, 'neutral': 99.2, 'contradiction': 0.5}\n",
      "\n",
      "ExxonMobil: total equity: {'amount': '+191650000000', 'unit': 'United States dollar', 'unit_QID': 'Q4917'} (point in time: December 31, 2019)\n",
      "{'entailment': 0.3, 'neutral': 99.3, 'contradiction': 0.4}\n",
      "\n",
      "Founder Technology: owned by: Founder Group\n",
      "{'entailment': 0.2, 'neutral': 99.3, 'contradiction': 0.4}\n",
      "\n",
      "ExxonMobil: market capitalization: {'amount': '+474414000000', 'unit': 'United States dollar', 'unit_QID': 'Q4917'} (point in time: August 22, 2025)\n",
      "{'entailment': 0.4, 'neutral': 99.3, 'contradiction': 0.3}\n",
      "\n",
      "ExxonMobil: total assets: {'amount': '+362597000000', 'unit': 'United States dollar', 'unit_QID': 'Q4917'} (point in time: December 31, 2019)\n",
      "{'entailment': 0.3, 'neutral': 99.5, 'contradiction': 0.2}\n",
      "\n",
      "ExxonMobil: net profit: {'amount': '+33680000000', 'unit': 'United States dollar', 'unit_QID': 'Q4917'} (point in time: 2024)\n",
      "{'entailment': 0.2, 'neutral': 99.5, 'contradiction': 0.2}\n",
      "\n",
      "ExxonMobil: total revenue: {'amount': '+349585000000', 'unit': 'United States dollar', 'unit_QID': 'Q4917'} (point in time: 2024)\n",
      "{'entailment': 0.3, 'neutral': 99.5, 'contradiction': 0.2}\n",
      "\n",
      "ExxonMobil: operating income: {'amount': '+48873000000', 'unit': 'United States dollar', 'unit_QID': 'Q4917'} (point in time: 2024)\n",
      "{'entailment': 0.2, 'neutral': 99.6, 'contradiction': 0.2}\n",
      "\n",
      "General Electric: operating income: {'amount': '+26267000000', 'unit': 'United States dollar', 'unit_QID': 'Q4917'} (point in time: 2013)\n",
      "{'entailment': 0.2, 'neutral': 99.6, 'contradiction': 0.2}\n",
      "\n",
      "Bolt: owned by: D1 Master Holdco I (proportion: {'amount': '+15.32', 'unit': 'percent', 'unit_QID': 'Q11229'}) (point in time: March 23, 2024), Mordor Management (proportion: {'amount': '+16.7', 'unit': 'percent', 'unit_QID': 'Q11229'}) (point in time: February 15, 2025), Mercedes-Benz Mobility Services (proportion: {'amount': '+7.41', 'unit': 'percent', 'unit_QID': 'Q11229'}) (point in time: February 15, 2025)\n",
      "{'entailment': 0.1, 'neutral': 99.8, 'contradiction': 0.1}\n",
      "\n",
      "Mapbox: estimated value: {'amount': '+1300000000', 'unit': 'United States dollar', 'unit_QID': 'Q4917'} (point in time: 2023) (reason for preferred rank: most recent value)\n",
      "{'entailment': 0.1, 'neutral': 99.8, 'contradiction': 0.1}\n",
      "\n",
      "Mapbox: investor: In-Q-Tel, Foundry Group (subject has role: series A round, series B round, series C round), Draper Fisher Jurvetson (subject has role: series B round, series C round), Thrive Capital (subject has role: series B round, series C round), Jon Winkelried (subject has role: series B round), SoftBank Vision Fund (subject has role: series C round, series D round, series D-1 round, series E round)\n",
      "{'entailment': 0.1, 'neutral': 99.8, 'contradiction': 0.1}\n",
      "\n",
      "Tesla, Inc.: owner of: Giga Nevada, Gigafactory Berlin-Brandenburg, Gigafactory Texas, Tesla Fremont Factory, Gigafactory Mexico, Giga Shanghai, Giga New York\n",
      "{'entailment': 0.0, 'neutral': 99.9, 'contradiction': 0.0}\n",
      "\n",
      "Gigafactory Berlin-Brandenburg: founded by: Tesla, Inc.\n",
      "{'entailment': 0.1, 'neutral': 99.9, 'contradiction': 0.0}\n",
      "\n",
      "Giga Shanghai: founded by: Tesla, Inc.\n",
      "{'entailment': 0.1, 'neutral': 99.9, 'contradiction': 0.0}\n",
      "\n",
      "Tesla Semi: energy storage capacity: {'amount': '+900000', 'unit': 'kilowatt-hour', 'unit_QID': 'Q182098'} (sourcing circumstances: circa) (calculated from: energy consumption, range)\n",
      "{'entailment': 0.0, 'neutral': 99.9, 'contradiction': 0.0}\n",
      "\n",
      "Giga New York: owned by: Tesla, Inc.\n",
      "{'entailment': 0.0, 'neutral': 99.9, 'contradiction': 0.0}\n",
      "\n",
      "Gigafactory Berlin-Brandenburg: owned by: Tesla, Inc.\n",
      "{'entailment': 0.0, 'neutral': 99.9, 'contradiction': 0.0}\n",
      "\n",
      "Giga Shanghai: owned by: Tesla, Inc.\n",
      "{'entailment': 0.0, 'neutral': 99.9, 'contradiction': 0.0}\n",
      "\n",
      "Tesla Semi: powered by: electric motor\n",
      "{'entailment': 0.1, 'neutral': 99.9, 'contradiction': 0.0}\n",
      "\n",
      "Elron Ventures Ltd: market capitalization: {'amount': '+489198000', 'unit': 'new shekel', 'unit_QID': 'Q131309'} (point in time: November 15, 2022)\n",
      "{'entailment': 0.0, 'neutral': 99.9, 'contradiction': 0.1}\n",
      "\n",
      "Gigafactory Berlin-Brandenburg: product or material produced: Tesla Model 3, Tesla Model Y\n",
      "{'entailment': 0.1, 'neutral': 99.9, 'contradiction': 0.0}\n",
      "\n",
      "Giga Shanghai: product or material produced: Tesla Model 3, Tesla Supercharger V3, Tesla Model Y\n",
      "{'entailment': 0.1, 'neutral': 99.9, 'contradiction': 0.0}\n",
      "\n",
      "Bolt: net profit: {'amount': '-92000000', 'unit': 'euro', 'unit_QID': 'Q4916'} (point in time: 2023)\n",
      "{'entailment': 0.0, 'neutral': 99.9, 'contradiction': 0.1}\n",
      "\n",
      "Bolt: total revenue: {'amount': '+1704000000', 'unit': 'euro', 'unit_QID': 'Q4916'} (point in time: 2023)\n",
      "{'entailment': 0.1, 'neutral': 99.9, 'contradiction': 0.1}\n",
      "\n",
      "Tesla, Inc.: EBITDA: {'amount': '+13558000000', 'unit': 'United States dollar', 'unit_QID': 'Q4917'} (point in time: 2023)\n",
      "{'entailment': 0.0, 'neutral': 100.0, 'contradiction': 0.0}\n",
      "\n",
      "Tesla, Inc.: total equity: {'amount': '+30189000000', 'unit': 'United States dollar', 'unit_QID': 'Q4917'} (point in time: December 31, 2021) (criterion used: fiscal year) (determination method or standard: United States Generally Accepted Accounting Principles)\n",
      "{'entailment': 0.0, 'neutral': 100.0, 'contradiction': 0.0}\n",
      "\n",
      "Tesla, Inc.: operating income: {'amount': '+7076000000', 'unit': 'United States dollar', 'unit_QID': 'Q4917'} (point in time: 2024)\n",
      "{'entailment': 0.0, 'neutral': 100.0, 'contradiction': 0.0}\n",
      "\n",
      "Tesla, Inc.: market capitalization: {'amount': '+903544000000', 'unit': 'United States dollar', 'unit_QID': 'Q4917'} (point in time: May 1, 2025)\n",
      "{'entailment': 0.0, 'neutral': 100.0, 'contradiction': 0.0}\n",
      "\n",
      "Tesla, Inc.: total assets: {'amount': '+62131000000', 'unit': 'United States dollar', 'unit_QID': 'Q4917'} (point in time: December 31, 2021) (criterion used: fiscal year) (determination method or standard: United States Generally Accepted Accounting Principles)\n",
      "{'entailment': 0.0, 'neutral': 100.0, 'contradiction': 0.0}\n",
      "\n",
      "Tesla, Inc.: net profit: {'amount': '+7091000000', 'unit': 'United States dollar', 'unit_QID': 'Q4917'} (point in time: 2024)\n",
      "{'entailment': 0.0, 'neutral': 100.0, 'contradiction': 0.0}\n",
      "\n",
      "Tesla, Inc.: total revenue: {'amount': '+97690000000', 'unit': 'United States dollar', 'unit_QID': 'Q4917'} (point in time: 2024)\n",
      "{'entailment': 0.0, 'neutral': 100.0, 'contradiction': 0.0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "claim = 'Elon Musk is the founder of Tesla, Inc.'\n",
    "\n",
    "fact_checker = FactChecker(include_external_ids=False, lang='en', device='cpu')\n",
    "results = fact_checker.check_claim(claim)\n",
    "\n",
    "for result in results:\n",
    "    print(result['hypothesis'])\n",
    "    print(result['entailment'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c436a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Austroasiatic languages, in recent classifications synonymous with Mon–Khmer, are a large language family of continental Southeast Asia, also scattered throughout India, Bangladesh, Nepal and the southern border of China. The name Austroasiatic comes from the Latin words for \"south\" and \"Asia\", hence \"South Asia\". Of these languages, only Vietnamese, Khmer, and Mon have a long-established recorded history, and only Vietnamese and Khmer have official status (in Vietnam and Cambodia, respectively). The rest of the languages are spoken by minority groups. Ethnologue identifies 168 Austroasiatic languages. These form thirteen established families (plus perhaps Shompen, which is poorly attested, as a fourteenth), which have traditionally been grouped into two, as Mon–Khmer and Munda. However, one recent classification posits three groups (Munda, Nuclear Mon-Khmer and Khasi-Khmuic) while another has abandoned Mon–Khmer as a taxon altogether, making it synonymous with the larger family. Austroasiatic languages have a disjunct distribution across India, Bangladesh, Nepal and Southeast Asia, separated by regions where other languages are spoken. They appear to be the autochthonous languages of Southeast Asia, with the neighboring Indo-Aryan, Tai–Kadai, Dravidian, Austronesian, and Sino-Tibetan languages being the result of later migrations.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('trex-dataset-sample.json', 'r') as f:\n",
    "    eval_data = json.load(f)\n",
    "\n",
    "eval_data[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d754d950",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/philippe.saade/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/philippe.saade/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "\n",
    "def is_pronoun(text):\n",
    "    if not text:\n",
    "        return False\n",
    "    tokens = word_tokenize(text)\n",
    "    tags = pos_tag(tokens)\n",
    "    return any(tag in {\"PRP\", \"PRP$\", \"WP\", \"WP$\"} for _, tag in tags)\n",
    "\n",
    "def map_triples_grouped_by_sentence(entry):\n",
    "    text = entry[\"text\"]\n",
    "    sentences = sent_tokenize(text)\n",
    "\n",
    "    # Compute sentence spans (char indices)\n",
    "    spans = []\n",
    "    start = 0\n",
    "    for sent in sentences:\n",
    "        end = start + len(sent)\n",
    "        spans.append((start, end))\n",
    "        start = end + 1  # assume 1 char separator\n",
    "\n",
    "    # Dict to collect all triples per sentence\n",
    "    sent_to_triples = defaultdict(list)\n",
    "\n",
    "    for triple in entry[\"triples\"]:\n",
    "        subj_id = triple[\"subject\"][\"uri\"].split(\"/\")[-1]\n",
    "        pred_id = triple[\"predicate\"][\"uri\"].split(\"/\")[-1]\n",
    "        obj_id = triple[\"object\"][\"uri\"].split(\"/\")[-1]\n",
    "\n",
    "        s_pos = triple[\"subject\"].get(\"boundaries\") or []\n",
    "        p_pos = triple[\"predicate\"].get(\"boundaries\") or []\n",
    "        o_pos = triple[\"object\"].get(\"boundaries\") or []\n",
    "\n",
    "        # Extract surface strings to filter pronouns\n",
    "        if s_pos:\n",
    "            subj_text = text[s_pos[0]:s_pos[1]]\n",
    "            if is_pronoun(subj_text):\n",
    "                continue\n",
    "        if o_pos:\n",
    "            obj_text = text[o_pos[0]:o_pos[1]]\n",
    "            if is_pronoun(obj_text):\n",
    "                continue\n",
    "\n",
    "        if not (s_pos or p_pos or o_pos):\n",
    "            continue\n",
    "\n",
    "        min_pos = min(p[0] for p in [s_pos, p_pos, o_pos] if p)\n",
    "        max_pos = max(p[1] for p in [s_pos, p_pos, o_pos] if p)\n",
    "\n",
    "        for idx, (s_start, s_end) in enumerate(spans):\n",
    "            if min_pos >= s_start and max_pos <= s_end:\n",
    "                sentence = sentences[idx]\n",
    "                sent_to_triples[sentence].append({\n",
    "                    \"subject_id\": subj_id,\n",
    "                    \"predicate_id\": pred_id,\n",
    "                    \"object_id\": obj_id\n",
    "                })\n",
    "                break\n",
    "\n",
    "    # Format into list of {\"sentence\": ..., \"triples\": [...]}\n",
    "    result = [\n",
    "        {\"sentence\": sent, \"triples\": triples}\n",
    "        for sent, triples in sent_to_triples.items()\n",
    "    ]\n",
    "\n",
    "    return result\n",
    "\n",
    "data = []\n",
    "for entry in eval_data:\n",
    "    data.extend(map_triples_grouped_by_sentence(entry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f5473fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philippe.saade/anaconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "  0%|          | 16/22364 [04:54<114:06:19, 18.38s/it]\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "500 Server Error: Internal Server Error for url: https://wd-textify.toolforge.org/?id=Q868%2CQ130191396%2CQ189506%2CQ1296719%2CQ21536495%2CQ30745180%2CQ8250872%2CQ794394%2CQ7723955%2CQ8508268%2CQ11943224%2CQ61904342%2CQ179541%2CQ8508269%2CQ61008298%2CQ97417348%2CQ16730135%2CQ6242292%2CQ4766262%2CQ49827839%2CQ41980%2CQ28174218%2CQ859%2CQ6242233%2CQ118868646%2CQ5362575%2CQ91784771%2CQ992271%2CQ4418716%2CQ24916215%2CQ4791109%2CQ108094966%2CQ106603322%2CQ20003016%2CQ111942367%2CQ49875965%2CQ66404134%2CQ3855427%2CQ3893430%2CQ6242325%2CQ97388086%2CQ1079293%2CQ6242372%2CQ2528551%2CQ65629570%2CQ2844594%2CQ106752478%2CQ18783854%2CQ29648227%2CQ6991694&pids=P7613%2CP737%2CP10059%2CP9106%2CP9563%2CP1935%2CP3126%2CP9686%2CP140%2CP10700%2CP5390%2CP10782%2CP5088%2CP6302%2CP12782%2CP1142%2CP6223%2CP3123%2CP802%2CP1463%2CP91%2CP8403%2CP12780%2CP7962%2CP3235%2CP9199%2CP184%2CP6488%2CP9212%2CP5004%2CP3732%2CP10717%2CP9625%2CP611%2CP9678%2CP9929%2CP135%2CP7378%2CP10670%2CP9430%2CP2080%2CP3413%2CP3232%2CP25%2CP10535%2CP5550%2CP863%2CP185%2CP3205%2CP7663&external_ids=False&format=json",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data))):\n\u001b[1;32m      7\u001b[0m     sentence \u001b[38;5;241m=\u001b[39m data[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m     results \u001b[38;5;241m=\u001b[39m fact_checker\u001b[38;5;241m.\u001b[39mcheck_claim(sentence)\n\u001b[1;32m      9\u001b[0m     data[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfact_checking_results\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m results\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfact_checking_data_with_results.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "Cell \u001b[0;32mIn[61], line 22\u001b[0m, in \u001b[0;36mFactChecker.check_claim\u001b[0;34m(self, claim)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_claim\u001b[39m(\u001b[38;5;28mself\u001b[39m, claim):\n\u001b[1;32m     21\u001b[0m     items, properties \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvector_search(claim)\n\u001b[0;32m---> 22\u001b[0m     statements \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_statements(items, properties)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(statements)):\n\u001b[1;32m     25\u001b[0m         statements[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhypothesis\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatement_to_string(\n\u001b[1;32m     26\u001b[0m             statements[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatement\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     27\u001b[0m         )\n",
      "Cell \u001b[0;32mIn[61], line 105\u001b[0m, in \u001b[0;36mFactChecker.prepare_statements\u001b[0;34m(self, items, properties)\u001b[0m\n\u001b[1;32m    103\u001b[0m qids \u001b[38;5;241m=\u001b[39m [q[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m items]\n\u001b[1;32m    104\u001b[0m pids \u001b[38;5;241m=\u001b[39m [p[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m properties]\n\u001b[0;32m--> 105\u001b[0m items_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_item_statements(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(qids), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(pids))\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(items)):\n\u001b[1;32m    108\u001b[0m     items[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m items_info[items[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQID\u001b[39m\u001b[38;5;124m'\u001b[39m]][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[61], line 71\u001b[0m, in \u001b[0;36mFactChecker.get_item_statements\u001b[0;34m(self, qids, pids)\u001b[0m\n\u001b[1;32m     69\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://wd-textify.toolforge.org\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m results \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url, params\u001b[38;5;241m=\u001b[39mparams, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders)\n\u001b[0;32m---> 71\u001b[0m results\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m     73\u001b[0m text \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/requests/models.py:1026\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1022\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1023\u001b[0m     )\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: https://wd-textify.toolforge.org/?id=Q868%2CQ130191396%2CQ189506%2CQ1296719%2CQ21536495%2CQ30745180%2CQ8250872%2CQ794394%2CQ7723955%2CQ8508268%2CQ11943224%2CQ61904342%2CQ179541%2CQ8508269%2CQ61008298%2CQ97417348%2CQ16730135%2CQ6242292%2CQ4766262%2CQ49827839%2CQ41980%2CQ28174218%2CQ859%2CQ6242233%2CQ118868646%2CQ5362575%2CQ91784771%2CQ992271%2CQ4418716%2CQ24916215%2CQ4791109%2CQ108094966%2CQ106603322%2CQ20003016%2CQ111942367%2CQ49875965%2CQ66404134%2CQ3855427%2CQ3893430%2CQ6242325%2CQ97388086%2CQ1079293%2CQ6242372%2CQ2528551%2CQ65629570%2CQ2844594%2CQ106752478%2CQ18783854%2CQ29648227%2CQ6991694&pids=P7613%2CP737%2CP10059%2CP9106%2CP9563%2CP1935%2CP3126%2CP9686%2CP140%2CP10700%2CP5390%2CP10782%2CP5088%2CP6302%2CP12782%2CP1142%2CP6223%2CP3123%2CP802%2CP1463%2CP91%2CP8403%2CP12780%2CP7962%2CP3235%2CP9199%2CP184%2CP6488%2CP9212%2CP5004%2CP3732%2CP10717%2CP9625%2CP611%2CP9678%2CP9929%2CP135%2CP7378%2CP10670%2CP9430%2CP2080%2CP3413%2CP3232%2CP25%2CP10535%2CP5550%2CP863%2CP185%2CP3205%2CP7663&external_ids=False&format=json"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "fact_checker = FactChecker(include_external_ids=False, lang='en', device='cpu')\n",
    "\n",
    "for i in tqdm(range(len(data))):\n",
    "    sentence = data[i]['sentence']\n",
    "    results = fact_checker.check_claim(sentence)\n",
    "    data[i]['fact_checking_results'] = results\n",
    "\n",
    "    with open('fact_checking_data_with_results.pkl', 'wb') as f:\n",
    "        pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cdec1c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philippe.saade/anaconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Search...\n",
      "['Q46758', 'Q17146193', 'Q8337', 'Q16011965', 'Q5410773', 'Q63113217', 'Q216930', 'Q336868', 'Q30739117', 'Q23891009', 'Q9011908', 'Q19975156', 'Q25934721', 'Q97867314', 'Q6130792', 'Q7372135', 'Q5364984', 'Q25752955', 'Q33129413', 'Q5727166', 'Q6107028', 'Q24302382', 'Q16466028', 'Q55720664', 'Q5606148', 'Q9105175', 'Q19974768', 'Q26691299', 'Q7791407', 'Q96707327', 'Q5482228', 'Q5423930', 'Q97738405', 'Q47467069', 'Q56559893', 'Q5671633', 'Q21113146', 'Q8003021', 'Q28016364', 'Q16030405', 'Q5671961', 'Q55153252', 'Q5673360', 'Q1414034', 'Q65620454', 'Q21167874', 'Q116291112', 'Q16066739', 'Q16066325', 'Q8001865']\n",
      "['P8371', 'P3818', 'P8359', 'P8360', 'P2629', 'P5940', 'P3650', 'P6658', 'P3132', 'P2860', 'P2637', 'P2540', 'P2913', 'P9191', 'P747', 'P4437', 'P2125', 'P6166', 'P1104', 'P10663', 'P1445', 'P1240', 'P577', 'P2635', 'P1434', 'P1433', 'P6886', 'P3306', 'P2679', 'P1080', 'P1922', 'P110', 'P9866', 'P1574', 'P5970', 'P872', 'P9215', 'P7937', 'P4584', 'P6524', 'P156', 'P478', 'P179', 'P155', 'P9071']\n",
      "Getting Statements Text...\n",
      "Found 16 statements\n",
      "Predicting Entailment...\n",
      "Harry Potter universe: fictional universe described in: Harry Potter, Harry Potter and the Philosopher's Stone, Harry Potter and the Goblet of Fire, Harry Potter and the Deathly Hallows, Harry Potter and the Half-Blood Prince, Harry Potter and the Chamber of Secrets, Harry Potter and the Prisoner of Azkaban, Harry Potter and the Order of the Phoenix, The Tales of Beedle the Bard, Quidditch Through the Ages, Fantastic Beasts and Where to Find Them, Wizarding World Digital, Harry Potter and the Deathly Hallows – Part 1, Book of Spells, Book of Potions, Harry Potter and the Order of the Phoenix, Fantastic Beasts, Severus Snape and the Marauders, Harry Potter and the Cursed Child, Fantastic Beasts and Where to Find Them, Fantastic Beasts: The Crimes of Grindelwald, Harry Potter prequel, Harry Potter and the Escape from Gringotts, Harry Potter: Wizards Unite, Harry Potter and the Philosopher's Stone, Harry Potter and the Chamber of Secrets, Harry Potter and the Prisoner of Azkaban, Harry Potter and the Goblet of Fire, Harry Potter and the Half-Blood Prince, Harry Potter and the Deathly Hallows, Harry Potter and the Deathly Hallows – Part 1, Harry Potter and the Deathly Hallows – Part 2, Harry Potter and the Cursed Child, Harry Potter and the Philosopher's Stone, Voldemort: Origins of the Heir, Lego Creator: Harry Potter and the Chamber of Secrets, A Very Potter Senior Year, A Very Potter Musical, Fantastic Beasts: The Secrets of Dumbledore, Wizarding World, Hogwarts Legacy, Harry Potter: A Magical Year, Hogwarts Library Books, Pottermore Presents, Fantastic Beasts and Where to Find Them: The Original Screenplay\n",
      "{'entailment': 99.9, 'neutral': 0.1, 'contradiction': 0.0}\n",
      "\n",
      "Harry Potter and the Deathly Hallows: form of creative work: novel\n",
      "{'entailment': 97.7, 'neutral': 2.2, 'contradiction': 0.0}\n",
      "\n",
      "Harry Potter and the Deathly Hallows: quotes work: 1 Corinthians 15\n",
      "{'entailment': 95.9, 'neutral': 4.1, 'contradiction': 0.0}\n",
      "\n",
      "Harry Potter: takes place in fictional universe: Harry Potter universe\n",
      "{'entailment': 93.8, 'neutral': 6.2, 'contradiction': 0.1}\n",
      "\n",
      "Harry Potter: publication date: November 4, 2001\n",
      "{'entailment': 90.0, 'neutral': 9.9, 'contradiction': 0.0}\n",
      "\n",
      "Harry Potter and the Deathly Hallows: takes place in fictional universe: Harry Potter universe\n",
      "{'entailment': 89.8, 'neutral': 10.1, 'contradiction': 0.0}\n",
      "\n",
      "Harry Potter and the Deathly Hallows: has edition or translation: Harry Potter and the Deathly Hallows, Harry Potter and the Deathly Hallows\n",
      "{'entailment': 87.3, 'neutral': 12.6, 'contradiction': 0.1}\n",
      "\n",
      "Harry Potter: publication date: 1997\n",
      "{'entailment': 87.2, 'neutral': 12.7, 'contradiction': 0.0}\n",
      "\n",
      "John Potter: writing language: English\n",
      "{'entailment': 8.2, 'neutral': 37.0, 'contradiction': 54.7}\n",
      "\n",
      "Harry Potter: illustrator: Mary GrandPré, Jim Kay, Kazu Kibuishi, Jonny Duddle, Andrew Davidson\n",
      "{'entailment': 34.5, 'neutral': 65.4, 'contradiction': 0.1}\n",
      "\n",
      "Henry Cottrell Rowland: writing language: English\n",
      "{'entailment': 2.7, 'neutral': 70.0, 'contradiction': 27.2}\n",
      "\n",
      "Harry Potter and the Deathly Hallows: follows: Harry Potter and the Half-Blood Prince\n",
      "{'entailment': 25.4, 'neutral': 74.6, 'contradiction': 0.0}\n",
      "\n",
      "Wizarding World: takes place in fictional universe: Harry Potter universe\n",
      "{'entailment': 11.3, 'neutral': 88.6, 'contradiction': 0.0}\n",
      "\n",
      "Harry Potter and the Deathly Hallows: part of the series: Harry Potter (follows: Harry Potter and the Half-Blood Prince) (series ordinal: 7)\n",
      "{'entailment': 10.6, 'neutral': 89.4, 'contradiction': 0.0}\n",
      "\n",
      "Harry Potter and the Deathly Hallows: last line: All was well.\n",
      "{'entailment': 2.6, 'neutral': 97.4, 'contradiction': 0.0}\n",
      "\n",
      "Harry Potter and the Deathly Hallows: first line: The two men appeared out of nowhere, a few yards apart in the narrow, moonlit lane.\n",
      "{'entailment': 2.1, 'neutral': 97.9, 'contradiction': 0.0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fact_checker = FactChecker(include_external_ids=False, lang='en', device='cpu')\n",
    "results = fact_checker.check_claim(\"J.K. Rowling wrote the Harry Potter series.\", verbose=True)\n",
    "\n",
    "for result in results:\n",
    "    print(result['hypothesis'])\n",
    "    print(result['entailment'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae3595e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
